# Vikas Gupta - Portfolio
Fall 2019 Project - Computational Photography Lab, Northwestern University

![Scanner Prototype](f19.png)
[Florian Willomitzer]

### Problem

Bring up 3D Scanning platform for real time motion capture. Using a Single Shot 3D method developed by Dr. Florian Willomitzer [Single-shot 3d motion picture camera with a dense point cloud by Willomitzer and Häusler](https://www.osapublishing.org/oe/abstract.cfm?uri=oe-25-19-23451)

![Scanner Prototype](3dscanner.jpg)
![Scanner Prototype](f19proto.jpg)

### Background

The single-shot 3D movie camera – 3D videos of fast scenes with unprecedented data quality. The information theoretical efficiency of triangulation (‘structured light’) systems is limited by the ‘ambiguity problem’. The concept of the ‘single shot 3D movie camera’ solves the ambiguity problem without relying on spatial or temporal codification of the projected signals. The camera sensors deliver 300,000 independent 3D points with high resolution from each 1 Mpix camera frame. A 3D sensor with these features allows for a continuous 3D measurement of fast moving or deforming objects, resulting in a continuous 3D movie. Like a hologram, each movie-frame encompasses the full 3D information about the object surface, and the observation perspective can be varied while watching the 3D movie (see related videos). [Florian Willomitzer 2017]

This work extends Prof. Florian Willomitzters Thesis *“Single Shot 3D Sensing Close to Physical Limits”* by researching 3D physical, information, and computational limits of single-shot 3D sensing

### Requirements
* Real-time processing of images from the aforementioned cameras (or offline sources),
* Generation of a dense, colorized point cloud
* Real-time rendering of generated point cloud 

### Architecture
![Block Diagram](3dscanblock.png)
[William Spies 2018]

The overall architecture and code was designed by William Spies, 2018 with some refacotring by me to simplify the workflow. 
* archiveDevice - emulate camera device with data i/o
* archiveInterface - data i/o
* calibration - parse and handle camera calibration data
* cameraDevice - handle a camera device
* cameraInterface -  interface to handle N cameras
* scanProcessing- manage image processing units (IPUs)
* scanProcessorUnit - handles create of singl IPUs - as a new thread
* scanGenerator - processes image information, generatcs point cloud
* main - set controllable values, set line projection, set capture mode (precaptured data or camera)


### Camera Calibration

*Instrinsics*
fx, fy, cx, cy, s;  // OpenCV camera matrix parameters
C, xP, yP; // Australis camera interior orientation parameters
k1, k2, k3; // Common radial distortion parameters
p1, p2; // Common tangential distortion parameters
b1, b2; // Affine non-orthogonality parameters
pix_height, pix_width; // Sensor pixel dimensions
cap_height, cap_width; // Capture region dimensions

*Extrinsics*
rotation; // Rotation matrix
translation; // Translation vector

### 
Overall these components together project line patterns via a projector, capture images from the camera(s), manipulate and process the images to recover line information, and process this for baseline/triangulation of depth information , and generate a real time point cloud that can be manipulated in real time. 

### Tools
* C++
* PCL
* Eigen
* GreyPoint Cameras
* Projector

### Work
* Collaborated with CPL team
* Brought up original Project / Camera Platform / Harness from Germany for real time processing
* Bring up new PointGrey Camera
* Render 3D uncalibrated point cloud in real time with 2 Camera setup
* Migrate development and environment from laptop a higher powered machine (from Intel i5 to i9 machine)

### Results
* [Github](https://github.com/vnmr/orthrus)
* [Video](3Dscanning.mov)

### Next Steps
* Fix Cameras interface issue on new server
* Calibrate Cameras 

### Future Work
* 
*

### Acknowledgements
* **Lead** Vikas Gupta
* **Advisors** Dr.Florian Willomitzer

Computational Photography Lab, Northwestern University
