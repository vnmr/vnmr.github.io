# under construction 
pardon the dust üê∫

# Publications

### 3D Human Pose Detection
![Pose](pose.jpg)
We propose a new deep learning architecture that introduces a deep channel filter 
and skeleton joint related constraints as losses to a previous 2-stage temporal 
deep CNN network to reduce joint position and motion errors for 3D 
video human body pose estimation. Our model outperforms the previous reported best 
result from the literature based on mean per-joint position error on the Human 3.6M 
benchmark by 1% This corresponds to a new state-of-the-art error reduction in all
categories, opening opportunites to combine these methods with future 3D human pose 
 estimators.

Contribution: Joint constraints as losses with temporal CNNs
Generalizable state of the art results in widely accepted benchmark

First Author, CVPR 2020 Submission

### 3D Shape Imaging
![3D Imaging](w19.jpg)
3D measurement of complicated surfaces with a tablet.
The introduced system allows for the three-dimensional measurement of extended 
specular surfaces with high surface normal variations. It consists only of a 
mobile handheld device (such as a Tablet) and exploits screen and front camera
for Deflectometry-based surface measurements. High quality surface measurements
are possible without the need for an offline calibration procedure. To compensate
for the small screen of a mobile device a multi-view registration technique is 
applied so that large surfaces can be densely reconstructed in their entirety. 
The mobile Deflectometry project is a first step towards a self-calibrating 
measurement procedure capable of taking 3D surface measurements in the wild 
and accessible to users with little to no technical imaging experience. 
We developed a ‚Äòsurface measurement app‚Äô that received an overwhelming amount of
media coverage.

Contribution: Hand Held instant 3D surface reconstruction
Co-Author, Optics Express 2019 submission


# Research
### HCI
A novel camera system that employs a natural Human Computer Interface.
An operator controls a wrist mounted camera with finger gestures. 
The camera gestures are detected, classified, and acted upon in real time.
The system is comprised of an embedded computer, inertial and force sensors
haptic, audio, and visual feedback components on a wearable substrate. 
Signals from sensors are processed and classified with classical singal and machine
learning technqiues. 
I researched, invented, and develeped a working prototype. 

Sole Inventor [Patent](https://patents.google.com/patent/WO2015131157A1/en) - Granted

[Youtube](https://www.youtube.com/watch?v=2Af4aUWo0HI\&feature=youtu.be\&t=28)

Cited by: Facebook Reality Labs, Amazon, Intel, Xiaomi, IBM, CTRL-labs, Essential

### Single Shot 3D Camera
The single-shot 3D movie camera ‚Äì 3D videos of fast scenes with unprecedented 
data quality. The information theoretical efficiency of triangulation 
(‚Äòstructured light‚Äô) systems is limited by the ‚Äòambiguity problem‚Äô. The 
concept of the ‚Äòsingle shot 3D movie camera‚Äô solves the ambiguity problem 
without relying on spatial or temporal codification of the projected signals.
This enables the single-shot acquisition of 3D data with unprecedented 
resolution. The sensor delivers 300,000 independent 3D points with high 
resolution from each 1 Mpix camera frame. A 3D sensor with these features 
allows for a continuous 3D measurement of fast moving or deforming objects, 
resulting in a continuous 3D movie. Like a hologram, each movie-frame 
encompasses the full 3D information about the object surface, and the observation
perspective can be varied while watching the 3D movie (see related videos).

This work extends Prof. Florian Willomitzters "Thesis Single Shot 3D 
Sensing Close to Physical Limits" by researching 3D physicak, information, 
and computational limits of single-shot 3D sensing

Contribution: In Progress - Real time 3D Reconstruction, Algorithms

[Youtube](https://www.youtube.com/watch?v=V6bOc3aBaHA)

### Swarm Robotics
Swarm Robotics platform with Prof. Michael Rubenstein, Northwestern
Reverse engineered pre-release SDK code/register settings for EVT Time of 
Flight sensor. Provided bug fixes and feedback to Time of Flight vendor 
Investigate and brought up space and power constrained SoC platform from micro-swarms. 

Provided feedback on sensor, SoC platform feasibility to lab for sensing, mapping, SLAM-type applications.

Contribution: Characterization of one dimensional sensing and SoC platform

# Projects

### Robot Vision Object Detection Obstacle Avoidance
Tohoku University, Japan, Robotics Summer School
![Obstacle Avoidance](tohoku.jpg)
As part of Prof. Kazuya Yoshida Space Robotics Challenge:
Develop a vision based mobile robotic navigation system for an uncertain environment.
I developed a custom RGBD segmentation, obstacle avoidance using Intel RealSense D435, 
Robot Operating System, for control of a lego mindstorm mobile robot.
In under 2 weeks I developed a system to successfully track a goal, while avoiding 
obstacles in a single episode physical environment.

Contribution: 1st attendee (any year) to develop vision based navigation
object detection, obstacle avoidance from scratch

### Learning Fundementals Poster Session
I participated in AI Singapore held at NUS and SUTD, Singapore. This was the 1st 
summer annual summer session. I decided to create an an interactive active learning 
poster session discussion on learning methods represented by code, math, and models. 

Contribution: Interactive Poster Session on Learning Fundamentals

### Various Robotics
Various individual and team projects such as span path planning with RRT
vision based object tracking, segmentation,
Manipulation using ROS, Gazebo, turtlesim, Sawyer, Baxter etc.

[Youtube](https://www.youtube.com/watch?v=bqnysqX-sqw) [Github](https://github.com/mschlafly/baxterplaysyahtzee)
